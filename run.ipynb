{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389dc62d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#install required dependencies\n",
    "!pip install -qU langgraph langchain langchain_openai chromadb beautifulsoup4\n",
    "!pip install -qU fastapi uvicorn python-dotenv pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29485c65",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
    "\n",
    "\n",
    "from getpass import getpass\n",
    " if \"OPENAI_API_KEY\" not in os.environ:\n",
    "     os.environ[\"OPENAI_API_KEY\"] = getpass(\"enter ur openAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c077ad",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "urls = [\n",
    "    \"https://blog.hubspot.com/marketing/what-is-content-marketing\",\n",
    "    \"https://www.semrush.com/blog/seo-copywriting/\",\n",
    "    \"https://neilpatel.com/blog/how-to-create-a-successful-social-media-marketing-campaign/\",\n",
    "]\n",
    "\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=512, chunk_overlap=100\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "#creating own vector store\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"marketing-blogs\",\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "print(\"vector store created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef26b8e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#### THe RAG Graph\n",
    "\n",
    "from typing import List, TypedDict\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1. Define the state for our graph\n",
    "# This state will be passed between nodes\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    generation: str\n",
    "    documents: List[str]\n",
    "\n",
    "\n",
    "# 2. Define the Nodes for our graph\n",
    "def retrieve_docs(state):\n",
    "    \"\"\"\n",
    "    Retrieves documents from the vector store.\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVING DOCUMENTS---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "    \"\"\"\n",
    "    print(\"---CHECKING DOCUMENT RELEVANCE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # LLM with function calling to grade relevance\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
    "        Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "        Here is the user question: {question} \\n\n",
    "        If the document contains keywords related to the user question, grade it as relevant.\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\n",
    "        Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\"\"\",\n",
    "        input_variables=[\"question\", \"document\"],\n",
    "    )\n",
    "\n",
    "    retrieval_grader = prompt | llm | JsonOutputParser()\n",
    "    \n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke({\"question\": question, \"document\": d.page_content})\n",
    "        grade = score['score']\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "    \n",
    "    return {\"documents\": filtered_docs, \"question\": question}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generates an answer using the retrieved documents.\n",
    "    \"\"\"\n",
    "    print(\"---GENERATING ANSWER---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a marketing assistant AI. Answer the user's question based on the context below:\n",
    "        \n",
    "        CONTEXT:\n",
    "        {context}\n",
    "        \n",
    "        QUESTION:\n",
    "        {question}\n",
    "        \n",
    "        ANSWER:\"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
    "    \n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "    \n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "\n",
    "# 3. Define the Conditional Edge\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer or end the process.\n",
    "    \"\"\"\n",
    "    print(\"---ASSESSING RELEVANCE & DECIDING NEXT STEP---\")\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    if not documents:\n",
    "        # All documents were filtered out, so we can't answer\n",
    "        print(\"---DECISION: NO RELEVANT DOCUMENTS, CANNOT ANSWER---\")\n",
    "        return \"cannot_answer\"\n",
    "    else:\n",
    "        # We have relevant documents, proceed to generation\n",
    "        print(\"---DECISION: RELEVANT DOCUMENTS FOUND, PROCEED TO GENERATE---\")\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8f1248",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "# Define the graph structure\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Add the nodes\n",
    "workflow.add_node(\"retrieve\", retrieve_docs)\n",
    "workflow.add_node(\"grade_documents\", grade_documents)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "workflow.add_node(\"cannot_answer\", generate) # If we can't answer, we still use the generate node to formulate a \"can't answer\" response.\n",
    "\n",
    "# Set the entry point\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "\n",
    "# Add the edges\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"generate\": \"generate\",\n",
    "        \"cannot_answer\": END, # End the flow if no docs are relevant\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "# Compile the graph into a runnable app\n",
    "app = workflow.compile()\n",
    "print(\"Graph compiled successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f7fa84",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "# Define a query\n",
    "inputs = {\"question\": \"What is the role of SEO copywriting in content marketing?\"}\n",
    "\n",
    "# Run the graph\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint.pprint(f\"Node: {key}\")\n",
    "        pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "    pprint.pprint(\"\\n---\\n\")\n",
    "\n",
    "# Print the final generation\n",
    "print(\"\\nFINAL ANSWER:\")\n",
    "pprint.pprint(value['generation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8f96c9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Another example\n",
    "inputs_2 = {\"question\": \"How can I create a successful social media campaign for a summer sale?\"}\n",
    "\n",
    "for output in app.stream(inputs_2):\n",
    "    for key, value in output.items():\n",
    "        pprint.pprint(f\"Node: {key}\")\n",
    "        pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "    pprint.pprint(\"\\n---\\n\")\n",
    "\n",
    "print(\"\\nFINAL ANSWER:\")\n",
    "pprint.pprint(value['generation'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
